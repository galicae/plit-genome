{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contamination analysis\n",
    "\n",
    "I don't want to run [ContScout](https://github.com/h836472/ContScout/) because it requires insane\n",
    "amounts of RAM/storage. Instead, I will align my draft genome against UniRef90 with mmseqs2, append\n",
    "taxonomic information to the better hits, and calculate the taxonomic makeup of each scaffold.\n",
    "\n",
    "We start by [downloading the UniRef90 database](mmseqs-download_uniref90.sh) and creating a mmseqs2\n",
    "index. While it is running, we will [prepare the draft genome](mmseqs-prepdb.sh) for alignment. When\n",
    "the download finishes, we can [align the draft genome](mmseqs-align.sh) against UniRef90, add \n",
    "taxonomic information, and save the result in a .tsv file, which we can afterwards read and parse\n",
    "at our leisure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.today().date().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"query\", \"target\", \"alnScore\", \"seqIdentity\", \"eVal\", \"qStart\", \"qEnd\", \"qLen\", \"tStart\",\n",
    "\"tEnd\", \"tLen\", \"queryOrfStart\", \"queryOrfEnd\", \"dbOrfStart\", \"dbOrfEnd\", \"taxid\",\n",
    "           \"level\", \"level_value\", \"taxonomy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result is close to 20Gb. To parse it, we first need to know how many lines it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m8 = \"/Volumes/scratch/pycnogonum/genome/draft/contamination/contam_tax.m8\"\n",
    "output = \"/Volumes/scratch/pycnogonum/genome/draft/contamination/chromosomes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$m8\" --out lines\n",
    "m8=$1\n",
    "\n",
    "wc -l $m8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lines = int(lines.split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will parse the file. Since we don't want to keep 20Gb in memory, we will extract only the\n",
    "relevant information: what we need is the taxonomic information of the hits _per\n",
    "scaffold/chromosome_. We will keep the corresponding columns of the `.m8` file and save them in\n",
    "separate files per chromosome/scaffold, for later processing. This is somewhat time-consuming, but\n",
    "can just run in the background, and we will only need to do it once*.\n",
    "\n",
    "\\* unless, of course, we change the genome, which has already happened once :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome = \"\"\n",
    "\n",
    "with open(m8) as f:\n",
    "    for i in tqdm(range(total_lines)):\n",
    "        line = f.readline().strip().split(\"\\t\")\n",
    "        query = line[0]\n",
    "        xx = int(line[12])\n",
    "        taxonomy = line[18]\n",
    "        if chromosome == \"\":\n",
    "            chromosome = query\n",
    "            out = open(f\"{output}/{chromosome}.tsv\", \"w\")\n",
    "        if query != chromosome:\n",
    "            out.close()\n",
    "            chromosome = query\n",
    "            out = open(f\"{output}/{chromosome}.tsv\", \"w\")\n",
    "        \n",
    "        out.write(\"\\t\".join(line) + \"\\n\")\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_taxonomic_distribution(sequence_path, columns, resolution=1000):\n",
    "    \"\"\"\n",
    "    Approximate the taxonomic distribution of a scaffold/pseudochromosome by aggregating hits within\n",
    "    ORFs. Essentially breaks the sequence into bins of size `resolution` but only uses detected ORFs\n",
    "    instead of blindly scanning with a sliding window. Assigns the taxon of the hit with the highest\n",
    "    score to each bin.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence_path : str\n",
    "        Path to the sequence file.\n",
    "    columns : list\n",
    "        Column names of the sequence file.\n",
    "    resolution : int\n",
    "        Resolution of the approximation (default: 1000).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Approximated taxonomic distribution; contains the absolute number of hits for each taxon\n",
    "        (Metazoa, unknown, Viridiplantae, uc_Bacteria, Fungi, various viruses, uc_Archaea,\n",
    "        uc_Eukaryota).\n",
    "    \"\"\"\n",
    "    raw = pd.read_csv(sequence_path, sep=\"\\t\", header=None)\n",
    "    raw.columns = columns\n",
    "    raw[\"queryOrfStart_approx\"] = raw[\"queryOrfStart\"] // resolution\n",
    "    raw[\"queryOrfEnd_approx\"] = raw[\"queryOrfEnd\"] // resolution\n",
    "    first_pass = raw.groupby(\"queryOrfStart_approx\").first().sort_values(\"queryOrfEnd\", ascending=False)\n",
    "    second_pass = first_pass.groupby(\"queryOrfEnd_approx\").first().sort_values(\"queryOrfEnd\", ascending=False)\n",
    "    return second_pass[\"taxonomy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_contents = os.listdir(f\"{output}\")\n",
    "sequences = [s for s in dir_contents if s.endswith('.tsv')]\n",
    "\n",
    "result = {}\n",
    "\n",
    "for sequence in tqdm(sequences):\n",
    "    result[sequence] = approximate_taxonomic_distribution(f\"{output}/{sequence}\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(result.values(), axis=1).fillna(0)\n",
    "df.columns = [k.split(\".\")[0] for k in result.keys()]\n",
    "# normalize each column by the sum of the column\n",
    "perc = df.div(df.sum(axis=0), axis=1)\n",
    "\n",
    "df = df.T\n",
    "perc = perc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"/Volumes/scratch/pycnogonum/genome/draft/contamination/scaffolds_taxonomic_distribution.tsv\", sep=\"\\t\")\n",
    "df = pd.read_csv(\"/Volumes/scratch/pycnogonum/genome/draft/contamination/scaffolds_taxonomic_distribution.tsv\", sep=\"\\t\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viruses = df.columns[df.columns.str.contains(\"vir\")]\n",
    "df['viruses'] = df[viruses].sum(axis=1)\n",
    "df.drop(columns=viruses, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Volumes/scratch/pycnogonum/genome/draft/contamination/scaffolds_taxonomic_distribution_collapsed_vir.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect = df.loc[perc[\"Metazoa\"] < 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect.to_csv(\"/Volumes/scratch/pycnogonum/genome/draft/contamination/scaffolds_taxonomic_distribution_suspect.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascc24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
